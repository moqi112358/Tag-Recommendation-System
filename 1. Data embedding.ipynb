{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))\n",
    "print(os.listdir(\"../raw-data/\"))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcaaaf2d05fbf3c184f83e1ce55e43f9c13e661f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# raw_data = pd.read_csv('../input/hackerearth-deep-learning-challenge-4/train.csv')\n",
    "import gensim \n",
    "import logging\n",
    "import pickle\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1426db59f759d8dd02640915681d6dc0331a27e1"
   },
   "outputs": [],
   "source": [
    "def read_input(raw_data):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    logging.info(\"reading raw data...this may take a while\")\n",
    "    l = len(raw_data)\n",
    "    article_list = []\n",
    "    title_list = []\n",
    "    id_list = []\n",
    "    for i in range(l):\n",
    "        line = raw_data['article'].iloc[i]\n",
    "        title = raw_data['title'].iloc[i]\n",
    "        id = raw_data['id'].iloc[i]\n",
    "        if (i % 10000 == 0):\n",
    "            logging.info(\"read {0} reviews\".format(i))\n",
    "        # do some pre-processing and return list of words for each article\n",
    "        line = gensim.utils.simple_preprocess(line)\n",
    "        title = gensim.utils.simple_preprocess(title)\n",
    "        article_list.append(line)\n",
    "        title_list.append(title)\n",
    "        id_list.append(id)\n",
    "    return id_list, title_list, article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcb56f7ce76a4bf5b18a1789a30e45fc708d4119"
   },
   "outputs": [],
   "source": [
    "output = open(\"./raw_to_list/train_list.pickle\", \"wb\")\n",
    "id_list, title_list, article_list = read_input(raw_data)\n",
    "pickle.dump([id_list, title_list, article_list], output)\n",
    "output.close()\n",
    "\n",
    "f=open('./raw_to_list/train_list.pickle','rb')  \n",
    "tmp=pickle.load(f)  \n",
    "f.close()\n",
    "id_list, title_list, article_list = tmp[0], tmp[1], tmp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import random\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "179d1ddb387da5ac55a48c186d90a12195ca6169"
   },
   "outputs": [],
   "source": [
    "def train(model, sentences, output_file='test.word2vec', train_sentences=None, epoch=5):\n",
    "    model.build_vocab(sentences)\n",
    "    if train_sentences:\n",
    "        model.train(train_sentences,total_examples=len(train_sentences),epochs=epoch)\n",
    "    #model.save_word2vec_format(output_file)\n",
    "    model.save(output_file)\n",
    "    return model\n",
    "\n",
    "def test_model_random(sentences, output_file):\n",
    "    #model = Word2Vec.load_word2vec_format(output_file, binary=False)\n",
    "    model = Word2Vec.load(output_file)\n",
    "    list_sentences = list(sentences)\n",
    "    for i in range(10):\n",
    "        sentence = random.choice(list_sentences)\n",
    "        word = random.choice(sentence)\n",
    "        print(\">>> %s: %s\" % (word, \" \".join(sentence)))\n",
    "        try:\n",
    "            for w,s in model.most_similar(word):\n",
    "                print(\"%.6f %s\" % (s, w))\n",
    "        except:\n",
    "            print(\"[WARN] low-frequency word\")\n",
    "\n",
    "def test_model(word_file, output_file):\n",
    "    model = Word2Vec.load(output_file)\n",
    "    print(\"# %s %s\" % (model, output_file))\n",
    "    for line in file(word_file):\n",
    "        word = line.strip().decode('utf8')\n",
    "        print(\">>> %s\" % (word))\n",
    "        try:\n",
    "            for w,s in model.most_similar(word):\n",
    "                print(\"%.6f %s\" % (s, w))\n",
    "        except:\n",
    "            print(\"[WARN] low-frequency word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "8c5f04ed412e37d9c3d958c4013b0edc67076b48"
   },
   "outputs": [],
   "source": [
    "model_title = gensim.models.Word2Vec(\n",
    "       sg=1, # skip-gram,\n",
    "       hs=0, #  negative sampling\n",
    "       negative=10, # “noise words” \n",
    "       sample=1e-3,\n",
    "       seed=0,\n",
    "       size=300,\n",
    "       window=2,\n",
    "       min_count=2,\n",
    "       workers=CPU_COUNT)\n",
    "\n",
    "train(model_title, title_list, './embedding/title_list.embedding', title_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5cec691572a369f52261a3708c19a1d61c0b460"
   },
   "outputs": [],
   "source": [
    "test_model_random(title_list, './embedding/title_list.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58eb1e0743f8100e65aa50de4f55aa0e294d8edc"
   },
   "outputs": [],
   "source": [
    "model_article = gensim.models.Word2Vec(\n",
    "       sg=1, # skip-gram\n",
    "       hs=0, # negative sampling\n",
    "       negative=5, # “noise words” \n",
    "       seed=0,\n",
    "       size=300,\n",
    "       sample=1e-5,\n",
    "       window=5,\n",
    "       min_count=5,\n",
    "       workers=CPU_COUNT)\n",
    "\n",
    "train(model_article, article_list, './embedding/article_list.embedding', article_list, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10331356d799781174fbffe65bf364e0cdaef574"
   },
   "outputs": [],
   "source": [
    "test_model_random(article_list, './embedding/article_list.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d2ccaeabf7086d0fb1eae28ac813e1a90a19988"
   },
   "outputs": [],
   "source": [
    "model_article.similarity('web', 'website')\n",
    "#model_article = gensim.models.Word2Vec.load('article_list.embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6947ba540a074981d529435f880c694be842a7e0"
   },
   "outputs": [],
   "source": [
    "vocab_title = {i:np.array(model_title.wv[i] for i in model_title.wv.index2word}\n",
    "vocab_article = {i:np.array(model_article.wv[i] for i in model_article.wv.index2word}\n",
    "\n",
    "output = open(\"title_vocab.pickle\", \"wb\")\n",
    "pickle.dump(vocab_title, output)\n",
    "output.close()\n",
    "\n",
    "output = open(\"article_vocab.pickle\", \"wb\")\n",
    "pickle.dump(vocab_article, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
